{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16fe9a57-ed66-4c6a-a52a-42e1b7c25c5c",
   "metadata": {},
   "source": [
    "## Reproducing result figures and evaluation metrics\n",
    "\n",
    "This notebook can be used to produce the different evaluation metrics and associated figures: \n",
    "\n",
    "* Evolution of kinetic energy over time\n",
    "* Energy spectrum as a function of the azimuthal wavenumber\n",
    "* Radial profiles of azimuthal velocity and potential vorticity\n",
    "* Zonal and residual energy spectrum based on the Bessel-Fourier transform\n",
    "* Hovmöller maps of the velocity components\n",
    "\n",
    "The notebook can also produce the statistical evaluation based on integrated metrics:\n",
    "\n",
    "* $Re$: Reynolds number\n",
    "* $E_{Z} / E_{T}$: Zonal energy ratio\n",
    "* $\\mathcal{Z}$: Enstrophy\n",
    "* $\\ell_{\\nu}$: Dissipation lengthscale\n",
    "* $\\mathcal{P}_\\mathcal{F}$: Injected power\n",
    "* $\\alpha_\\nu^{\\Upsilon}$: Ratio of dissipative processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca9ffb-e4b0-44b2-b182-a209ff7e3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import tqdm\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as plt_lines\n",
    "\n",
    "plt.rcParams.update({\n",
    "  'mathtext.fontset': 'cm'\n",
    "})\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jnr\n",
    "\n",
    "jax.config.update(\n",
    "  'jax_enable_x64', True\n",
    ")\n",
    "\n",
    "import models.imex_solver as imex\n",
    "from models.qg_annulus import (\n",
    "    QgAnnulus, \n",
    "    dynamical_solver,\n",
    "    cartesian_forcing,\n",
    "    average,\n",
    "    reynolds,\n",
    "    azimuthal_spectrum,\n",
    "    hankel_spectrum\n",
    ")\n",
    "from utils import (\n",
    "    from_m,\n",
    "    quad_r,\n",
    "    coef_r,\n",
    "    hankel_kernels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4fe4b3-e33b-4744-88d2-a79068d73038",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '' # your save path (as used in eval.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b809b29d-519e-43ac-93cc-600ccac16539",
   "metadata": {},
   "source": [
    "### Alternative models - kinetic energy evolutions and azimuthal spectra $E_{T}(m)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036426c4-9546-49f4-820f-b65231b04b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading configuration\n",
    "cfg_name = 'iii'\n",
    "cfg_data = os.path.join(save_path, cfg_name)\n",
    "cfg_path = os.path.join('../data', cfg_name)\n",
    "eq, *_ = QgAnnulus.load(os.path.join(cfg_path, 'snapshot.h5'))\n",
    "\n",
    "# Dataset (and associated evaluation) name\n",
    "data_name = 'continuous-turnover'\n",
    "with h5py.File(os.path.join(cfg_path, data_name + '_dataset.h5'), 'r') as f:\n",
    "    coarse_factor = f.attrs['coarse_factor']\n",
    "\n",
    "eq_coarse = QgAnnulus(\n",
    "    E=eq.E,\n",
    "    cte_beta=eq.cte_beta,\n",
    "    radius_ratio=eq.s_i / eq.s_o,\n",
    "    n_m=int((eq.n_m - 1) / coarse_factor) + 1,\n",
    "    n_s=int((eq.n_s - 1) / coarse_factor) + 1\n",
    ")\n",
    "\n",
    "def alt_models_stats(\n",
    "    name: str,\n",
    "    file_path: str,\n",
    "    eq: QgAnnulus\n",
    "):\n",
    "    comp_path = file_path + '.alt_models_stats.npz'\n",
    "    if os.path.isfile(comp_path):\n",
    "        comp_data = np.load(comp_path)\n",
    "        return (\n",
    "            comp_data['time'],\n",
    "            comp_data['total_ke_t'],\n",
    "            comp_data['zonal_ke_t'],\n",
    "            comp_data['m_spectra']\n",
    "        )\n",
    "    else:\n",
    "        total_ke_t = []\n",
    "        zonal_ke_t = []\n",
    "        m_spectra = []\n",
    "        \n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            time = np.array(f['time'])\n",
    "            samples = len(time)\n",
    "            samples_digits = len(str(samples))\n",
    "            print('Computing kinetic energy evolution and azimuthal spectrum for {} ({} samples)'.format(name, str(samples)))\n",
    "            pbar = tqdm.tqdm(range(samples), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "            for i in pbar:\n",
    "                i_str = str(i).zfill(samples_digits)\n",
    "                us_m = np.array(f['us_m_' + i_str])\n",
    "                up_m = np.array(f['up_m_' + i_str])\n",
    "    \n",
    "                total_ke_t.append(\n",
    "                    0.5 * (average(eq, us_m) + average(eq, up_m))\n",
    "                )\n",
    "                zonal_ke_t.append(\n",
    "                    0.5 * average(eq, up_m[[0]])\n",
    "                )\n",
    "                m_spectra.append(\n",
    "                    (azimuthal_spectrum(eq, us_m) + azimuthal_spectrum(eq, up_m)) / eq.surf\n",
    "                )\n",
    "        np.savez(\n",
    "            comp_path, \n",
    "            time=time, \n",
    "            total_ke_t=total_ke_t, \n",
    "            zonal_ke_t=zonal_ke_t, \n",
    "            m_spectra=m_spectra\n",
    "        )\n",
    "        return (\n",
    "            time,\n",
    "            np.array(total_ke_t),\n",
    "            np.array(zonal_ke_t),\n",
    "            np.array(m_spectra)\n",
    "        )\n",
    "\n",
    "# Reference\n",
    "path_dns = os.path.join(cfg_data, data_name + '_eval_dns.h5')\n",
    "time_dns, total_ke_t_dns, zonal_ke_t_dns, m_spectra_dns = alt_models_stats(\n",
    "    name='DNS', \n",
    "    file_path=path_dns, \n",
    "    eq=eq\n",
    ")\n",
    "\n",
    "# Models\n",
    "path_learn = os.path.join(cfg_data, data_name + '_eval_learn.h5')\n",
    "time_learn, total_ke_t_learn, zonal_ke_t_learn, m_spectra_learn = alt_models_stats(\n",
    "    name='`Learned` model', \n",
    "    file_path=path_learn, \n",
    "    eq=eq_coarse\n",
    ")\n",
    "\n",
    "path_hdiff = os.path.join(cfg_data, data_name + '_eval_hdiff.h5')\n",
    "time_hdiff, total_ke_t_hdiff, zonal_ke_t_hdiff, m_spectra_hdiff = alt_models_stats(\n",
    "    name='`Hyperdiffusivity` model', \n",
    "    file_path=path_hdiff, \n",
    "    eq=eq_coarse\n",
    ")\n",
    "\n",
    "path_0 = os.path.join(cfg_data, data_name + '_eval_0.h5')\n",
    "time_0, total_ke_t_0, zonal_ke_t_0, m_spectra_0 = alt_models_stats(\n",
    "    name='`Under-resolved` model',\n",
    "    file_path=path_0,     \n",
    "    eq=eq_coarse\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(7.5, 4.0), dpi=120)\n",
    "\n",
    "axs[0].plot(time_dns,   total_ke_t_dns,   label=r'$\\text{DNS}$', color='k')\n",
    "axs[0].plot(time_learn, total_ke_t_learn, label=r'$\\tau \\equiv \\mathcal{M}$', color='tab:blue')\n",
    "axs[0].plot(time_hdiff, total_ke_t_hdiff, label=r'$\\tau \\equiv d(m)$', color='tab:orange')\n",
    "axs[0].plot(time_0,     total_ke_t_0,     label=r'$\\tau \\equiv 0$', color='tab:green')\n",
    "\n",
    "axs[0].plot(time_dns,   zonal_ke_t_dns,   alpha=0.6, linestyle='--', color='k')\n",
    "axs[0].plot(time_learn, zonal_ke_t_learn, alpha=0.6, linestyle='--', color='tab:blue')\n",
    "axs[0].plot(time_hdiff, zonal_ke_t_hdiff, alpha=0.6, linestyle='--', color='tab:orange')\n",
    "axs[0].plot(time_0,     zonal_ke_t_0,     alpha=0.6, linestyle='--', color='tab:green')\n",
    "\n",
    "axs[0].axvspan(time_dns[0], time_0[0], color='darkgrey', alpha=0.3)\n",
    "axs[0].ticklabel_format(useMathText=True)\n",
    "axs[0].set_xlabel(r'$t$', fontsize=15)\n",
    "axs[0].set_xticks([0.01, 0.015, 0.02, 0.025])\n",
    "axs[0].set_ylabel(r'$\\text{Kinetic \\,\\, energy}$', fontsize=15)\n",
    "axs[0].set_xlim(right=time_dns[-1])\n",
    "axs[0].set_ylim(bottom=0, top=4.5e7)\n",
    "E_T = plt_lines.Line2D([], [], color='k', label=r'$E_T$')\n",
    "E_Z = plt_lines.Line2D([], [], color='k', linestyle='--', alpha=0.2, label=r'$E_Z$')\n",
    "axs[0].legend(handles=[E_T, E_Z], fontsize=13, frameon=False)\n",
    "axs[0].tick_params(reset=True, axis='y', which='both', direction='in')\n",
    "\n",
    "axs[1].loglog(np.arange(eq.n_m) + 1,        np.mean(m_spectra_dns,   axis=0), label=r'$\\text{DNS}$', color='k')\n",
    "axs[1].loglog(np.arange(eq_coarse.n_m) + 1, np.mean(m_spectra_learn, axis=0), label=r'$\\tau \\equiv \\mathcal{M}$', color='tab:blue')\n",
    "axs[1].loglog(np.arange(eq_coarse.n_m) + 1, np.mean(m_spectra_hdiff, axis=0), label=r'$\\tau \\equiv d(m)$', color='tab:orange')\n",
    "axs[1].loglog(np.arange(eq_coarse.n_m) + 1, np.mean(m_spectra_0,     axis=0), label=r'$\\tau \\equiv 0$', color='tab:green')\n",
    "axs[1].set_xlabel(r'$m + 1$', fontsize=15)\n",
    "axs[1].set_ylabel(r'$E_T(m)$', fontsize=15)\n",
    "axs[1].set_xlim((1, eq.n_m))\n",
    "axs[1].legend(fontsize=13, frameon=False)\n",
    "axs[1].tick_params(reset=True, axis='both', which='both', direction='in')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f99f1-c609-4425-aefa-7dac61f67ee2",
   "metadata": {},
   "source": [
    "### Zonal strutures - radial profiles of the azimuthal velocity $u_{\\varphi}(s)$ and potential vorticity $q(s)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a4018-2e75-4e61-b462-07b77fee50a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading configuration\n",
    "cfg_name = 'i'\n",
    "cfg_data = os.path.join(save_path, cfg_name)\n",
    "cfg_path = os.path.join('../data', cfg_name)\n",
    "eq, *_ = QgAnnulus.load(os.path.join(cfg_path, 'snapshot.h5'))\n",
    "\n",
    "# Dataset (and associated evaluation) name\n",
    "data_name = 'continuous-turnover'\n",
    "with h5py.File(os.path.join(cfg_path, data_name + '_dataset.h5'), 'r') as f:\n",
    "    coarse_factor = f.attrs['coarse_factor']\n",
    "\n",
    "eq_coarse = QgAnnulus(\n",
    "    E=eq.E,\n",
    "    cte_beta=eq.cte_beta,\n",
    "    radius_ratio=eq.s_i / eq.s_o,\n",
    "    n_m=int((eq.n_m - 1) / coarse_factor) + 1,\n",
    "    n_s=int((eq.n_s - 1) / coarse_factor) + 1\n",
    ")\n",
    "\n",
    "def zonal_structures(\n",
    "    name: str,\n",
    "    file_path: str,\n",
    "    eq: QgAnnulus\n",
    "):\n",
    "    comp_path = file_path + '.zonal_structures.npz'\n",
    "    if os.path.isfile(comp_path):\n",
    "        comp_data = np.load(comp_path)\n",
    "        return (\n",
    "            comp_data['mean_up_r'],\n",
    "            comp_data['std_up_r'],\n",
    "            comp_data['mean_q_r']\n",
    "        )\n",
    "    else:\n",
    "        up_r = []\n",
    "        q_r = []\n",
    "        \n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            time = np.array(f['time'])\n",
    "            samples = len(time)\n",
    "            samples_digits = len(str(samples))\n",
    "            print('Computing radial profiles of the azimuthal velocity and potential vorticity for {} ({} samples)'.format(name, str(samples)))\n",
    "            pbar = tqdm.tqdm(range(samples), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "            for i in pbar:\n",
    "                i_str = str(i).zfill(samples_digits)\n",
    "                up_m = np.array(f['up_m_' + i_str])\n",
    "                om_m = np.array(f['om_m_' + i_str])\n",
    "                \n",
    "                up_r.append(\n",
    "                    np.mean(from_m(up_m, eq.n_phi), axis=0)\n",
    "                )\n",
    "                q_r.append(\n",
    "                    (np.mean(from_m(om_m, eq.n_phi), axis=0) + 2 / eq.E) / eq.height\n",
    "                )\n",
    "                \n",
    "        mean_up_r = np.mean(up_r, axis=0)\n",
    "        std_up_r = np.std(up_r, axis=0)\n",
    "        mean_q_r = np.mean(q_r, axis=0)\n",
    "        np.savez(\n",
    "            comp_path, \n",
    "            mean_up_r=mean_up_r, \n",
    "            std_up_r=std_up_r, \n",
    "            mean_q_r=mean_q_r\n",
    "        )\n",
    "        return (\n",
    "            mean_up_r,\n",
    "            std_up_r,\n",
    "            mean_q_r,\n",
    "        )\n",
    "\n",
    "# Reference\n",
    "path_dns = os.path.join(cfg_data, data_name + '_eval_dns.h5')\n",
    "mean_up_r_dns, std_up_r_dns, mean_q_r_dns = zonal_structures(\n",
    "    name='DNS', \n",
    "    file_path=path_dns, \n",
    "    eq=eq\n",
    ")\n",
    "\n",
    "# Models\n",
    "path_learn = os.path.join(cfg_data, data_name + '_eval_learn.h5')\n",
    "mean_up_r_learn, std_up_r_learn, mean_q_r_learn = zonal_structures(\n",
    "    name='`Learned` model', \n",
    "    file_path=path_learn, \n",
    "    eq=eq_coarse\n",
    ")\n",
    "\n",
    "path_hdiff = os.path.join(cfg_data, data_name + '_eval_hdiff.h5')\n",
    "mean_up_r_hdiff, std_up_r_hdiff, mean_q_r_hdiff = zonal_structures(\n",
    "    name='`Hyperdiffusivity` model', \n",
    "    file_path=path_hdiff, \n",
    "    eq=eq_coarse\n",
    ")\n",
    "\n",
    "path_0 = os.path.join(cfg_data, data_name + '_eval_0.h5')\n",
    "mean_up_r_0, std_up_r_0, mean_q_r_0 = zonal_structures(\n",
    "    name='`Under-resolved` model',\n",
    "    file_path=path_0,     \n",
    "    eq=eq_coarse\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(7.5, 3.75), dpi=120)\n",
    "\n",
    "axs[0].plot(eq.s_grid,        mean_up_r_dns,   label=r'$\\text{DNS}$', color='k')\n",
    "axs[0].plot(eq_coarse.s_grid, mean_up_r_learn, label=r'$\\tau \\equiv \\mathcal{M}$', color='tab:blue')\n",
    "axs[0].plot(eq_coarse.s_grid, mean_up_r_hdiff, label=r'$\\tau \\equiv d(m)$', color='tab:orange')\n",
    "axs[0].plot(eq_coarse.s_grid, mean_up_r_0,     label=r'$\\tau \\equiv 0$', color='tab:green')\n",
    "\n",
    "axs[0].fill_between(eq.s_grid,        mean_up_r_dns   - std_up_r_dns,   mean_up_r_dns   + std_up_r_dns,   alpha=0.2, color='k')\n",
    "axs[0].fill_between(eq_coarse.s_grid, mean_up_r_learn - std_up_r_learn, mean_up_r_learn + std_up_r_learn, alpha=0.2, color='tab:blue')\n",
    "axs[0].fill_between(eq_coarse.s_grid, mean_up_r_hdiff - std_up_r_hdiff, mean_up_r_hdiff + std_up_r_hdiff, alpha=0.2, color='tab:orange')\n",
    "axs[0].fill_between(eq_coarse.s_grid, mean_up_r_0     - std_up_r_0,     mean_up_r_0     + std_up_r_0,     alpha=0.2, color='tab:green')\n",
    "\n",
    "axs[0].ticklabel_format(style='scientific', scilimits=(0,0), useMathText=True)\n",
    "axs[0].set_xlabel(r'$s$', fontsize=15)\n",
    "axs[0].set_ylabel(r'$\\langle u_\\varphi \\rangle_\\varphi(s)$', fontsize=15)\n",
    "axs[0].set_xlim((eq.s_i, eq.s_o))\n",
    "axs[0].tick_params(reset=True, axis='both', which='both', direction='in')\n",
    "\n",
    "axs[1].plot(eq.s_grid,        mean_q_r_dns,   label=r'$\\text{DNS}$', color='k')\n",
    "axs[1].plot(eq_coarse.s_grid, mean_q_r_learn, label=r'$\\tau \\equiv \\mathcal{M}$', color='tab:blue')\n",
    "axs[1].plot(eq_coarse.s_grid, mean_q_r_hdiff, label=r'$\\tau \\equiv d(m)$', color='tab:orange')\n",
    "axs[1].plot(eq_coarse.s_grid, mean_q_r_0,     label=r'$\\tau \\equiv 0$', color='tab:green')\n",
    "axs[0].axhline(0, color='darkgrey', linestyle='--')\n",
    "\n",
    "axs[1].ticklabel_format(style='scientific', scilimits=(0,0), useMathText=True)\n",
    "axs[1].set_xlabel(r'$s$', fontsize=15)\n",
    "axs[1].set_ylabel(r'$\\langle q \\rangle_\\varphi(s)$', fontsize=15)\n",
    "axs[1].set_xlim((eq.s_i, eq.s_o))\n",
    "axs[1].legend(fontsize=13, frameon=False)\n",
    "axs[1].tick_params(reset=True, axis='both', which='both', direction='in')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d609ca7-a7af-45f3-9999-d143091d9acc",
   "metadata": {},
   "source": [
    "### Spectral analysis - zonal and residual Bessel-Fourier spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0e535-37a8-4944-9c32-40ac39e8cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading configuration\n",
    "cfg_name = 'ii'\n",
    "cfg_data = os.path.join(save_path, cfg_name)\n",
    "cfg_path = os.path.join('../data', cfg_name)\n",
    "eq, *_ = QgAnnulus.load(os.path.join(cfg_path, 'snapshot.h5'))\n",
    "\n",
    "# Dataset (and associated evaluation) name\n",
    "data_name = 'continuous-turnover'\n",
    "with h5py.File(os.path.join(cfg_path, data_name + '_dataset.h5'), 'r') as f:\n",
    "    coarse_factor = f.attrs['coarse_factor']\n",
    "\n",
    "eq_coarse = QgAnnulus(\n",
    "    E=eq.E,\n",
    "    cte_beta=eq.cte_beta,\n",
    "    radius_ratio=eq.s_i / eq.s_o,\n",
    "    n_m=int((eq.n_m - 1) / coarse_factor) + 1,\n",
    "    n_s=int((eq.n_s - 1) / coarse_factor) + 1\n",
    ")\n",
    "\n",
    "print('Computing high-resolution grid Hankel roots and kernels...')\n",
    "m_roots, kernels = hankel_kernels(eq)\n",
    "k_weber_orr = m_roots[0, :]\n",
    "dk = np.diff(k_weber_orr)\n",
    "bins = np.zeros(len(k_weber_orr) + 1, np.float64)\n",
    "bins[ 0] = k_weber_orr[ 0] - dk[ 0]/2\n",
    "bins[-1] = k_weber_orr[-1] + dk[-1]/2\n",
    "bins[1:-1] = k_weber_orr[:-1] + dk/2\n",
    "dk = np.diff(bins)\n",
    "\n",
    "print('Computing coarse-resolution grid Hankel roots and kernels...')\n",
    "m_roots_coarse, kernels_coarse = hankel_kernels(eq_coarse)\n",
    "k_weber_orr_coarse = m_roots_coarse[0, :]\n",
    "dk_coarse = np.diff(k_weber_orr_coarse)\n",
    "bins_coarse = np.zeros(len(k_weber_orr_coarse) + 1, np.float64)\n",
    "bins_coarse[ 0] = k_weber_orr_coarse[ 0] - dk_coarse[ 0]/2\n",
    "bins_coarse[-1] = k_weber_orr_coarse[-1] + dk_coarse[-1]/2\n",
    "bins_coarse[1:-1] = k_weber_orr_coarse[:-1] + dk_coarse/2\n",
    "dk_coarse = np.diff(bins_coarse)\n",
    "\n",
    "def spectral_analysis(\n",
    "    name: str,\n",
    "    file_path: str,\n",
    "    eq: QgAnnulus,\n",
    "    m_roots: jnp.ndarray,\n",
    "    kernels: jnp.ndarray,\n",
    "    pad: bool\n",
    "):\n",
    "    comp_path = file_path + '.spectral_analysis.npz'\n",
    "    if os.path.isfile(comp_path):\n",
    "        comp_data = np.load(comp_path)\n",
    "        return (\n",
    "            comp_data['er_k'],\n",
    "            comp_data['ez_k'],\n",
    "        )\n",
    "    else:\n",
    "        er_k = []\n",
    "        ez_k = []\n",
    "        \n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            time = np.array(f['time'])\n",
    "            samples = len(time)\n",
    "            samples_digits = len(str(samples))\n",
    "            print('Computing zonal and residual Bessel-Fourier spectra for {} ({} samples)'.format(name, str(samples)))\n",
    "            pbar = tqdm.tqdm(range(samples), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "            for i in pbar:\n",
    "                i_str = str(i).zfill(samples_digits)\n",
    "                us_m = np.array(f['us_m_' + i_str])\n",
    "                up_m = np.array(f['up_m_' + i_str])\n",
    "\n",
    "                if pad:\n",
    "                    us_m = np.pad(us_m, ((0, eq.n_m - us_m.shape[0]), (0, 0)))\n",
    "                    us_r = jax.vmap(coef_r)(us_m)\n",
    "                    us_r = 1 / np.sqrt(1 / coarse_factor) * np.pad(us_r, ((0, 0), (0, eq.n_s - us_r.shape[1])))\n",
    "                    us_m = jax.vmap(coef_r)(us_r)\n",
    "                    up_m = np.pad(up_m, ((0, eq.n_m - up_m.shape[0]), (0, 0)))\n",
    "                    up_r = jax.vmap(coef_r)(up_m)\n",
    "                    up_r = 1 / np.sqrt(1 / coarse_factor) * np.pad(up_r, ((0, 0), (0, eq.n_s - up_r.shape[1])))\n",
    "                    up_m = jax.vmap(coef_r)(up_r)\n",
    "    \n",
    "                if i % (samples // 5) == 0:\n",
    "                    us_k = hankel_spectrum(eq, m_roots, kernels, us_m)\n",
    "                    up_k = hankel_spectrum(eq, m_roots, kernels, up_m)\n",
    "                    if pad:\n",
    "                        us_k = us_k[:eq_coarse.n_m, :eq_coarse.n_s]\n",
    "                        up_k = up_k[:eq_coarse.n_m, :eq_coarse.n_s]\n",
    "                    er_k.append(\n",
    "                        (us_k + up_k)[1:] / eq.surf\n",
    "                    )\n",
    "                us_0 = hankel_spectrum(eq, m_roots, kernels, us_m, n_max_m=1)[0]\n",
    "                up_0 = hankel_spectrum(eq, m_roots, kernels, up_m, n_max_m=1)[0]\n",
    "                if pad:\n",
    "                    us_0 = us_0[:eq_coarse.n_s]\n",
    "                    up_0 = up_0[:eq_coarse.n_s]\n",
    "                ez_k.append(\n",
    "                    (us_0 + up_0) / eq.surf\n",
    "                )\n",
    "        np.savez(\n",
    "            comp_path, \n",
    "            er_k=er_k, \n",
    "            ez_k=ez_k, \n",
    "        )\n",
    "        return (\n",
    "            np.array(er_k),\n",
    "            np.array(ez_k)\n",
    "        )\n",
    "\n",
    "def residual_binning(\n",
    "    er_k: np.ndarray,\n",
    "    m_roots: np.ndarray,\n",
    "    bins: np.ndarray,\n",
    "    dk: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    return [\n",
    "        scipy.stats.binned_statistic(m_roots[1:].flatten(), er_k[i].flatten(), statistic='sum', bins=bins)[0] / dk \n",
    "        for i in range(len(er_k))\n",
    "    ]\n",
    "\n",
    "# Reference\n",
    "path_dns = os.path.join(cfg_data, data_name + '_eval_dns.h5')\n",
    "er_k_dns, ez_k_dns = spectral_analysis(\n",
    "    name='DNS', \n",
    "    file_path=path_dns, \n",
    "    eq=eq,\n",
    "    m_roots=m_roots,\n",
    "    kernels=kernels,\n",
    "    pad=False\n",
    ")\n",
    "er_k_dns = residual_binning(\n",
    "    er_k_dns, m_roots, bins, dk\n",
    ")\n",
    "\n",
    "# Models\n",
    "path_learn = os.path.join(cfg_data, data_name + '_eval_learn.h5')\n",
    "er_k_learn, ez_k_learn = spectral_analysis(\n",
    "    name='`Learned` model', \n",
    "    file_path=path_learn, \n",
    "    eq=eq,\n",
    "    m_roots=m_roots,\n",
    "    kernels=kernels,\n",
    "    pad=True\n",
    ")\n",
    "er_k_learn = residual_binning(\n",
    "    er_k_learn, m_roots_coarse, bins_coarse, dk_coarse\n",
    ")\n",
    "\n",
    "path_hdiff = os.path.join(cfg_data, data_name + '_eval_hdiff.h5')\n",
    "er_k_hdiff, ez_k_hdiff = spectral_analysis(\n",
    "    name='`Hyperdiffusivity` model', \n",
    "    file_path=path_hdiff, \n",
    "    eq=eq,\n",
    "    m_roots=m_roots,\n",
    "    kernels=kernels,\n",
    "    pad=True\n",
    ")\n",
    "er_k_hdiff = residual_binning(\n",
    "    er_k_hdiff, m_roots_coarse, bins_coarse, dk_coarse\n",
    ")\n",
    "\n",
    "path_0 = os.path.join(cfg_data, data_name + '_eval_0.h5')\n",
    "er_k_0, ez_k_0 = spectral_analysis(\n",
    "    name='`Under-resolved` model',\n",
    "    file_path=path_0,\n",
    "    eq=eq,\n",
    "    m_roots=m_roots,\n",
    "    kernels=kernels,\n",
    "    pad=True\n",
    ")\n",
    "er_k_0 = residual_binning(\n",
    "    er_k_0, m_roots_coarse, bins_coarse, dk_coarse\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(ncols=1, nrows=1, figsize=(3.75, 3.75), dpi=120)\n",
    "\n",
    "axs.loglog(bins[1:] - dk/2,               np.mean(er_k_dns,   axis=0), label=r'$\\text{DNS}$', color='k')\n",
    "axs.loglog(bins_coarse[1:] - dk_coarse/2, np.mean(er_k_learn, axis=0), label=r'$\\tau \\equiv \\mathcal{M}$', color='tab:blue')\n",
    "axs.loglog(bins_coarse[1:] - dk_coarse/2, np.mean(er_k_hdiff, axis=0), label=r'$\\tau \\equiv d(m)$', color='tab:orange')\n",
    "axs.loglog(bins_coarse[1:] - dk_coarse/2, np.mean(er_k_0,     axis=0), label=r'$\\tau \\equiv 0$', color='tab:green')\n",
    "\n",
    "axs.loglog(m_roots[0],        np.mean(ez_k_dns,   axis=0), linestyle='--', alpha=0.5, color='k', )\n",
    "axs.loglog(m_roots_coarse[0], np.mean(ez_k_learn, axis=0), linestyle='--', alpha=0.5, color='tab:blue')\n",
    "axs.loglog(m_roots_coarse[0], np.mean(ez_k_hdiff, axis=0), linestyle='--', alpha=0.5, color='tab:orange')\n",
    "axs.loglog(m_roots_coarse[0], np.mean(ez_k_0,     axis=0), linestyle='--', alpha=0.5, color='tab:green')\n",
    "\n",
    "axs.set_xlabel(r'$k$', fontsize=15)\n",
    "axs.set_ylabel(r'$\\text{Kinetic \\,\\, energy \\,\\, spectra}$', fontsize=15)\n",
    "axs.set_xlim((m_roots[0, 0], m_roots[0, -1]))\n",
    "axs.legend(fontsize=13, frameon=False, handlelength=1)\n",
    "axs.tick_params(reset=True, axis='both', which='both', direction='in')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf521abb-a17f-4ef1-aa8c-ddb9bb5f66aa",
   "metadata": {},
   "source": [
    "### Temporal patterns - Hovmöller maps of the azimuthal and radial velocities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131ad09-d698-4aea-9bd3-6e8e80329399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading configuration\n",
    "cfg_name = 'ii'\n",
    "cfg_data = os.path.join(save_path, cfg_name)\n",
    "cfg_path = os.path.join('../data', cfg_name)\n",
    "eq, *_ = QgAnnulus.load(os.path.join(cfg_path, 'snapshot.h5'))\n",
    "\n",
    "# Dataset (and associated evaluation) name\n",
    "data_name = 'continuous-turnover'\n",
    "with h5py.File(os.path.join(cfg_path, data_name + '_dataset.h5'), 'r') as f:\n",
    "    coarse_factor = f.attrs['coarse_factor']\n",
    "\n",
    "eq_coarse = QgAnnulus(\n",
    "    E=eq.E,\n",
    "    cte_beta=eq.cte_beta,\n",
    "    radius_ratio=eq.s_i / eq.s_o,\n",
    "    n_m=int((eq.n_m - 1) / coarse_factor) + 1,\n",
    "    n_s=int((eq.n_s - 1) / coarse_factor) + 1\n",
    ")\n",
    "\n",
    "def temporal_patterns(\n",
    "    name: str,\n",
    "    file_path: str,\n",
    "    eq: QgAnnulus,\n",
    "    radial_idx: int\n",
    "):\n",
    "    comp_path = file_path + '.temporal_patterns.npz'\n",
    "    if os.path.isfile(comp_path):\n",
    "        comp_data = np.load(comp_path)\n",
    "        return (\n",
    "            comp_data['time'],\n",
    "            comp_data['up_ravg'],\n",
    "            comp_data['us_pavg']\n",
    "        )\n",
    "    else:\n",
    "        up_ravg = []\n",
    "        us_pavg = []\n",
    "        \n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            time = np.array(f['time'])\n",
    "            samples = len(time)\n",
    "            samples_digits = len(str(samples))\n",
    "            print('Computing radial/azimuthal profiles of the azimuthal/radial velocities for {} ({} samples)'.format(name, str(samples)))\n",
    "            pbar = tqdm.tqdm(range(samples), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "            for i in pbar:\n",
    "                i_str = str(i).zfill(samples_digits)\n",
    "                us_m = np.array(f['us_m_' + i_str])\n",
    "                up_m = np.array(f['up_m_' + i_str])\n",
    "    \n",
    "                up_ravg.append(\n",
    "                    np.mean(from_m(up_m, eq.n_phi), axis=0)\n",
    "                )\n",
    "                us_pavg.append(\n",
    "                    from_m(us_m, eq.n_phi)[:, radial_idx]\n",
    "                )\n",
    "        np.savez(\n",
    "            comp_path, \n",
    "            time=time, \n",
    "            up_ravg=up_ravg, \n",
    "            us_pavg=us_pavg\n",
    "        )\n",
    "        return (\n",
    "            time,\n",
    "            np.array(up_ravg),\n",
    "            np.array(us_pavg)\n",
    "        )\n",
    "\n",
    "# Reference\n",
    "path_dns = os.path.join(cfg_data, data_name + '_eval_dns.h5')\n",
    "time_dns, up_ravg_dns, us_pavg_dns = temporal_patterns(\n",
    "    name='DNS', \n",
    "    file_path=path_dns, \n",
    "    eq=eq,\n",
    "    radial_idx=100\n",
    ")\n",
    "\n",
    "# Model\n",
    "path_learn = os.path.join(cfg_data, data_name + '_eval_learn.h5')\n",
    "time_learn, up_ravg_learn, us_pavg_learn = temporal_patterns(\n",
    "    name='`Learned` model', \n",
    "    file_path=path_learn, \n",
    "    eq=eq_coarse,\n",
    "    radial_idx=20\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(ncols=1, nrows=2, figsize=(7.5, 5.0), constrained_layout=True)\n",
    "\n",
    "up_r_mag = 0.4*np.max(np.abs(up_ravg_dns))\n",
    "\n",
    "cbar = axs[0].contourf(\n",
    "    time_dns, \n",
    "    eq.s_grid, \n",
    "    up_ravg_dns.T, \n",
    "    levels=50, vmin=-up_r_mag, vmax=up_r_mag, cmap='RdBu_r', extend='both'\n",
    ")\n",
    "axs[1].contourf(\n",
    "    time_learn, \n",
    "    eq_coarse.s_grid, \n",
    "    up_ravg_learn.T, \n",
    "    levels=50, vmin=-up_r_mag, vmax=up_r_mag, cmap='RdBu_r', extend='both'\n",
    ")\n",
    "\n",
    "axs[0].set_title(r'$(a) \\,\\, \\text{DNS}$', fontsize=12, loc='left')\n",
    "axs[0].set_ylabel(r'$s$', fontsize=15)\n",
    "axs[1].set_title(r'$(b) \\,\\, \\tau \\equiv \\mathcal{M}$', fontsize=12, loc='left')\n",
    "axs[1].set_ylabel(r'$s$', fontsize=15)\n",
    "axs[1].set_xlabel(r'$t$', fontsize=15)\n",
    "\n",
    "x, y = 0.16, -0.03\n",
    "width = 0.75\n",
    "height = 0.02\n",
    "cbar_axs = fig.add_axes([x, y, width, height])\n",
    "cbar_axs.set_in_layout(False)\n",
    "fig.colorbar(cbar, cax=cbar_axs, orientation='horizontal', aspect=5, shrink=0.2)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=1, nrows=2, figsize=(7.5, 5.0), constrained_layout=True)\n",
    "\n",
    "us_p_mag = 0.35*np.max(np.abs(us_pavg_dns))\n",
    "\n",
    "# Only show 1 turnover time\n",
    "turnover_time = 1.7e-4\n",
    "\n",
    "start_idx_dns = np.argmin(np.abs(time_dns - time_learn[0]))\n",
    "end_idx_dns = np.argmin(np.abs(time_dns - (time_learn[0] + turnover_time)))\n",
    "cbar = axs[0].contourf(\n",
    "    np.linspace(0, 2 * np.pi, eq.n_phi, endpoint=False), \n",
    "    time_dns[start_idx_dns:end_idx_dns], \n",
    "    us_pavg_dns[start_idx_dns:end_idx_dns], \n",
    "    levels=50, vmin=-us_p_mag, vmax=us_p_mag, cmap='PuOr', extend='both'\n",
    ")\n",
    "\n",
    "end_idx_learn = np.argmin(np.abs(time_learn - (time_learn[0] + turnover_time)))\n",
    "axs[1].contourf(\n",
    "    np.linspace(0, 2 * np.pi, eq_coarse.n_phi, endpoint=False), \n",
    "    time_learn[:end_idx_learn], \n",
    "    us_pavg_learn[:end_idx_learn], \n",
    "    levels=50, vmin=-us_p_mag, vmax=us_p_mag, cmap='PuOr', extend='both'\n",
    ")\n",
    "\n",
    "axs[0].set_title(r'$(a) \\,\\, \\text{DNS}$', fontsize=12, loc='left')\n",
    "axs[0].set_ylabel(r'$t$', fontsize=15)\n",
    "axs[0].set_yticks(np.linspace(0.010175, 0.010300, 6))\n",
    "axs[1].set_title(r'$(b) \\,\\, \\tau \\equiv \\mathcal{M}$', fontsize=12, loc='left')\n",
    "axs[1].set_ylabel(r'$t$', fontsize=15)\n",
    "axs[1].set_xlabel(r'$\\varphi$', fontsize=15)\n",
    "axs[1].set_yticks(np.linspace(0.010175, 0.010300, 6))\n",
    "\n",
    "x, y = 0.18, -0.03\n",
    "width = 0.75\n",
    "height = 0.02\n",
    "cbar_axs = fig.add_axes([x, y, width, height])\n",
    "fig.colorbar(cbar, cax=cbar_axs, orientation='horizontal', aspect=5, shrink=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317c461-d927-4ab5-8072-2d4201ee6031",
   "metadata": {},
   "source": [
    "### Integrated quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3619b491-1b44-466c-8e94-5860b8c742a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forcing_prep(\n",
    "    eq: QgAnnulus,\n",
    "    dx_f: float,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Cartesian forcing described in\n",
    "    \n",
    "    Zonal jets experiments in the gas giants’ zonostrophic regime.\n",
    "    D. Lemasquerier, B. Favier and M. Le Bars.\n",
    "    Icarus 390 (2023).\n",
    "    \"\"\"\n",
    "    nx = int(2 * eq.s_o / dx_f + 1)\n",
    "    ny = nx\n",
    "    dx = 2 * eq.s_o / (nx - 1)\n",
    "    dy = dx\n",
    "    \n",
    "    x_lins, y_lins = np.meshgrid(np.arange(nx), np.arange(ny), indexing='ij')\n",
    "    amp_grid = (-1)**(x_lins + 1) * (-1)**(y_lins + 1)\n",
    "    x_grid, y_grid = np.meshgrid(-eq.s_o + dx * np.arange(nx), -eq.s_o + dy * np.arange(ny), indexing='ij')\n",
    "    iso_grid = np.sqrt(x_grid*x_grid + y_grid*y_grid)\n",
    "    \n",
    "    pump_position = (iso_grid >= eq.s_i + 0.5 * dx) & \\\n",
    "                    (iso_grid <= eq.s_o - 0.5 * dx)\n",
    "    \n",
    "    amp = amp_grid[pump_position]\n",
    "    x = x_grid[pump_position]\n",
    "    y = y_grid[pump_position]\n",
    "    return x, y, amp\n",
    "\n",
    "dx_f = 0.08\n",
    "radius_f = 0.04\n",
    "a_f = 2e10\n",
    "xpump, ypump, amppump = forcing_prep(eq, dx_f)\n",
    "\n",
    "def integrated_quantities(\n",
    "    name: str,\n",
    "    file_path: str,\n",
    "    eq: QgAnnulus\n",
    "):\n",
    "    comp_path = file_path + '.integrated_quantities.npz'\n",
    "    if os.path.isfile(comp_path):\n",
    "        comp_data = np.load(comp_path)\n",
    "        return (\n",
    "            comp_data['re'],\n",
    "            comp_data['ez_ratio'],\n",
    "            comp_data['ens'],\n",
    "            comp_data['diss_l'],\n",
    "            comp_data['power'],\n",
    "            comp_data['v_diss'],\n",
    "            comp_data['f_diss']\n",
    "        )\n",
    "    else:\n",
    "        re = []\n",
    "        ez_ratio = []\n",
    "        ens = []\n",
    "        diss_l = []\n",
    "        power = []\n",
    "        v_diss = []\n",
    "        f_diss = []\n",
    "\n",
    "        rr, pp = np.meshgrid(eq.s_grid, 2 * np.pi * np.arange(eq.n_phi) / eq.n_phi)\n",
    "        n_pumps = len(xpump)\n",
    "        \n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            time = np.array(f['time'])\n",
    "            samples = len(time)\n",
    "            samples_digits = len(str(samples))\n",
    "            print('Computing integrated quantities for {} ({} samples)'.format(name, str(samples)))\n",
    "            pbar = tqdm.tqdm(range(samples), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "            for i in pbar:\n",
    "                i_str = str(i).zfill(samples_digits)\n",
    "                us_m = np.array(f['us_m_' + i_str])\n",
    "                up_m = np.array(f['up_m_' + i_str])\n",
    "                om_m = np.array(f['om_m_' + i_str])\n",
    "\n",
    "                et = 0.5 * (average(eq, us_m) + average(eq, up_m))\n",
    "                ez = 0.5 * average(eq, up_m[[0]])\n",
    "\n",
    "                up = from_m(up_m, eq.n_phi)\n",
    "                us = from_m(us_m, eq.n_phi)\n",
    "\n",
    "                xx = rr * np.cos(pp)\n",
    "                yy = rr * np.sin(pp)\n",
    "\n",
    "                ux = us * np.cos(pp) - up * np.sin(pp)\n",
    "                uy = us * np.sin(pp) + up * np.cos(pp)\n",
    "\n",
    "                def __pump_power__(xpump, ypump, amppump):\n",
    "                    si = jnp.sqrt((xx - xpump)**2 + (yy - ypump)**2)\n",
    "                    return amppump / si**2 * (1 - jnp.exp(-si**2 / radius_f**2)) * (-(yy - ypump)*ux + (xx - xpump)*uy)\n",
    "\n",
    "                fdotu = 0.5 * a_f * radius_f**2 * np.sum(jax.vmap(__pump_power__)(xpump, ypump, amppump), axis=0)\n",
    "                fdotu_tot = 2 * np.pi * np.mean(fdotu, axis=0)\n",
    "                fpower = np.real(quad_r(fdotu_tot * eq.s_grid)) / eq.surf\n",
    "                \n",
    "                re.append(\n",
    "                    reynolds(eq, us_m, up_m)\n",
    "                )\n",
    "                ez_ratio.append(\n",
    "                    ez / et\n",
    "                )\n",
    "                ens.append(\n",
    "                    0.5 * average(eq, om_m)\n",
    "                )\n",
    "                diss_l.append(\n",
    "                    np.sqrt(et / ens[-1])\n",
    "                )\n",
    "                \n",
    "                power.append(\n",
    "                    fpower\n",
    "                )\n",
    "                v_diss.append(\n",
    "                    2 * ens[-1]\n",
    "                )\n",
    "                f_diss.append(\n",
    "                    fpower - v_diss[-1]\n",
    "                )\n",
    "        np.savez(\n",
    "            comp_path, \n",
    "            re=re, \n",
    "            ez_ratio=ez_ratio, \n",
    "            ens=ens,\n",
    "            diss_l=diss_l,\n",
    "            power=power,\n",
    "            v_diss=v_diss,\n",
    "            f_diss=f_diss\n",
    "        )\n",
    "        return (\n",
    "            np.array(re),\n",
    "            np.array(ez_ratio),\n",
    "            np.array(ens),\n",
    "            np.array(diss_l),\n",
    "            np.array(power),\n",
    "            np.array(v_diss),\n",
    "            np.array(f_diss)\n",
    "        )\n",
    "\n",
    "configs = [\n",
    "    ('i', 'continuous-turnover'), \n",
    "    ('ii', 'continuous-turnover'), \n",
    "    ('iii', 'continuous-turnover')\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=1, nrows=len(configs), dpi=120)\n",
    "\n",
    "row_labels = ['DNS', '`Learned` model', '`Hyperdiffusivity` model', '`Under-resolved` model']\n",
    "col_labels = [r'$Re$', r'$E_Z / E_T$', r'$\\mathcal{Z}$', r'$\\ell_\\nu$', r'$\\mathcal{P}_\\mathcal{F}$', r'$\\alpha_\\nu^\\Upsilon$']\n",
    "\n",
    "for i, (cfg_name, data_name) in enumerate(configs):\n",
    "    cfg_data = os.path.join(save_path, cfg_name)\n",
    "    cfg_path = os.path.join('../data', cfg_name)\n",
    "    eq, *_ = QgAnnulus.load(os.path.join(cfg_path, 'snapshot.h5'))\n",
    "    \n",
    "    # Dataset (and associated evaluation) name\n",
    "    with h5py.File(os.path.join(cfg_path, data_name + '_dataset.h5'), 'r') as f:\n",
    "        coarse_factor = f.attrs['coarse_factor']\n",
    "    print('Computing integrated quantities for config ({})'.format(cfg_name))\n",
    "\n",
    "    eq_coarse = QgAnnulus(\n",
    "        E=eq.E,\n",
    "        cte_beta=eq.cte_beta,\n",
    "        radius_ratio=eq.s_i / eq.s_o,\n",
    "        n_m=int((eq.n_m - 1) / coarse_factor) + 1,\n",
    "        n_s=int((eq.n_s - 1) / coarse_factor) + 1\n",
    "    )\n",
    "\n",
    "    # Reference\n",
    "    path_dns = os.path.join(cfg_data, data_name + '_eval_dns.h5')\n",
    "    re_dns, ez_ratio_dns, ens_dns, diss_l_dns, power_dns, v_diss_dns, f_diss_dns = integrated_quantities(\n",
    "        name='DNS', \n",
    "        file_path=path_dns, \n",
    "        eq=eq\n",
    "    )\n",
    "\n",
    "    # Models\n",
    "    path_learn = os.path.join(cfg_data, data_name + '_eval_learn.h5')\n",
    "    re_learn, ez_ratio_learn, ens_learn, diss_l_learn, power_learn, v_diss_learn, f_diss_learn = integrated_quantities(\n",
    "        name='`Learned` model', \n",
    "        file_path=path_learn, \n",
    "        eq=eq_coarse\n",
    "    )\n",
    "\n",
    "    path_hdiff = os.path.join(cfg_data, data_name + '_eval_hdiff.h5')\n",
    "    re_hdiff, ez_ratio_hdiff, ens_hdiff, diss_l_hdiff, power_hdiff, v_diss_hdiff, f_diss_hdiff = integrated_quantities(\n",
    "        name='`Hyperdiffusivity` model', \n",
    "        file_path=path_hdiff, \n",
    "        eq=eq_coarse\n",
    "    )\n",
    "    \n",
    "    path_0 = os.path.join(cfg_data, data_name + '_eval_0.h5')\n",
    "    re_0, ez_ratio_0, ens_0, diss_l_0, power_0, v_diss_0, f_diss_0 = integrated_quantities(\n",
    "        name='`Under-resolved` model',\n",
    "        file_path=path_0,\n",
    "        eq=eq_coarse\n",
    "    )\n",
    "\n",
    "    f_ratio_dns = np.mean(f_diss_dns) / (np.mean(f_diss_dns) + np.mean(v_diss_dns))\n",
    "    f_ratio_learn = np.mean(f_diss_learn) / (np.mean(f_diss_learn) + np.mean(v_diss_learn))\n",
    "    f_ratio_hdiff = np.mean(f_diss_hdiff) / (np.mean(f_diss_hdiff) + np.mean(v_diss_hdiff))\n",
    "    f_ratio_0   = np.mean(f_diss_0) / (np.mean(f_diss_0) + np.mean(v_diss_0))\n",
    "    cell_values = np.stack((\n",
    "        ['%.0f' % np.mean(re_dns)  , '%.3f' % np.mean(ez_ratio_dns),   '%.2e' % np.mean(ens_dns),   \n",
    "         '%.2e' % np.mean(diss_l_dns),   '%.2e' % np.mean(power_dns),   '%.3f' % np.mean(f_ratio_dns)], \n",
    "        ['%.0f' % np.mean(re_learn), '%.3f' % np.mean(ez_ratio_learn), '%.2e' % np.mean(ens_learn), \n",
    "         '%.2e' % np.mean(diss_l_learn), '%.2e' % np.mean(power_learn), '%.3f' % np.mean(f_ratio_learn)],\n",
    "        ['%.0f' % np.mean(re_hdiff), '%.3f' % np.mean(ez_ratio_hdiff), '%.2e' % np.mean(ens_hdiff), \n",
    "         '%.2e' % np.mean(diss_l_hdiff), '%.2e' % np.mean(power_hdiff), '%.3f' % np.mean(f_ratio_hdiff)],\n",
    "        ['%.0f' % np.mean(re_0)    , '%.3f' % np.mean(ez_ratio_0),     '%.2e' % np.mean(ens_0),     \n",
    "         '%.2e' % np.mean(diss_l_0),     '%.2e' % np.mean(power_0),     '%.3f' % np.mean(f_ratio_0)]\n",
    "    ))\n",
    "\n",
    "    cfg_ax = axs[i] if len(configs) > 1 else axs\n",
    "    cfg_ax.axis('off')\n",
    "    cfg_ax.table(cellText=cell_values, rowLabels=row_labels, colLabels=col_labels, loc='top', cellLoc='left', fontsize=50)\n",
    "    cfg_ax.text(-0.4, 1.7, r'$\\text{Config \\,\\, ' + '(' + cfg_name + ')}$')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
